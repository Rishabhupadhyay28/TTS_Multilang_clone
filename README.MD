
## ğŸ—£ï¸ **Multilingual Text-to-Speech & Voice Cloning System**

### ğŸš€ Built with FastAPI Â· Streamlit Â· Coqui YourTTS



### ğŸ“˜ **Overview**

This project integrates **Text-to-Speech (TTS)** and **Voice Cloning** capabilities into one multilingual system.
It allows users to input text in any language, automatically translate it (if unsupported), and generate realistic speech output â€” including cloned voices from short audio samples.
The system runs **locally on CPU** and supports **English, French, and Portuguese**, with automatic translation for other languages.


### ğŸŒ **Key Features**

âœ… **Multilingual Text-to-Speech** â€” Converts text into human-like speech in multiple languages.
âœ… **Voice Cloning** â€” Clone a speakerâ€™s voice from a short sample (e.g., `.wav`, `.mp3`).
âœ… **Auto-Translation** â€” Detects unsupported languages and translates them using Deep Translator.
âœ… **FastAPI Backend** â€” Provides REST APIs for `/tts/` and `/clone/` endpoints.
âœ… **Streamlit Frontend** â€” Simple and elegant UI for interactive text or file input.
âœ… **Runs on CPU** â€” Fully functional without GPU dependency.
âœ… **Open Source** â€” Built using the Coqui `TTS` library and Python ecosystem.

---

### ğŸ§  **Model Used**

**Model:** `tts_models/multilingual/multi-dataset/your_tts`
**Library:** [Coqui TTS](https://github.com/coqui-ai/TTS)

* Architecture: Based on **VITS (Variational Inference Text-to-Speech)**
* Features:

  * Zero-shot **Voice Cloning**
  * **Multilingual** synthesis (English ğŸ‡¬ğŸ‡§, French ğŸ‡«ğŸ‡·, Portuguese ğŸ‡§ğŸ‡·)
  * Real-time inference
  * Runs locally without GPU

---

### âš™ï¸ **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Streamlit Frontend         â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ User inputs text or uploads audio  â”‚
â”‚ â€¢ Sends requests to FastAPI backend  â”‚
â”‚ â€¢ Plays or downloads generated audio â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            FastAPI Backend            â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ Handles /tts/ and /clone/ endpoints â”‚
â”‚ â€¢ Uses Deep Translator for languages  â”‚
â”‚ â€¢ Invokes YourTTS model for inference â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             YourTTS Model             â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ Multilingual TTS + Voice Cloning    â”‚
â”‚ â€¢ Generates human-like audio output   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Output and Storage Layer       â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ â€¢ Saves generated .wav files locally  â”‚
â”‚ â€¢ Returns path or audio to frontend   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ§© **Folder Structure**

```
tts_multilang_clone/
â”‚
â”œâ”€â”€ app.py                # FastAPI backend
â”œâ”€â”€ app_ui.py             # Streamlit frontend
â”œâ”€â”€ requirements.txt      # Required libraries
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tts_engine.py     # Handles TTS generation
â”‚   â”œâ”€â”€ voice_cloning.py  # Handles cloning logic
â”‚   â”œâ”€â”€ preprocessing.py  # Cleans and converts audio
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Global configuration
â”‚
â”œâ”€â”€ outputs/              # Generated speech files
â”œâ”€â”€ uploads/              # Uploaded audio samples
â””â”€â”€ README.md
```

---

### ğŸ› ï¸ **Installation Guide**

#### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Rishabhupadhyay28/TTS_Multilang_clone.git
cd multilingual-voice-cloning-tts
```

#### 2ï¸âƒ£ Create and Activate Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate      # On Windows
# or
source venv/bin/activate   # On macOS/Linux
```

#### 3ï¸âƒ£ Install Requirements

```bash
pip install -r requirements.txt
```

#### 4ï¸âƒ£ Run the Backend (FastAPI)

```bash
uvicorn app:app --reload
```

Backend will start at â†’ `http://127.0.0.1:8000`

#### 5ï¸âƒ£ Run the Frontend (Streamlit)

Open a new terminal and run:

```bash
streamlit run app_ui.py
```

Frontend will open in browser â†’ `http://localhost:8501`

---

### ğŸ¤ **How It Works**

1. **Text-to-Speech Mode**

   * Enter any text â†’ select language â†’ click **Generate Speech**
   * Output speech plays automatically or can be downloaded.

2. **Voice Cloning Mode**

   * Upload a voice sample (WAV/MP3)
   * Enter any text to be spoken
   * The model clones the voice and speaks the text naturally.

3. **Language Auto-Translation**

   * If a user inputs Hindi or other unsupported text, itâ€™s automatically translated to English before speech generation.

---

### ğŸ§© **Libraries Used**

| Library             | Purpose                            |
| ------------------- | ---------------------------------- |
| **FastAPI**         | Backend API framework              |
| **Streamlit**       | Frontend UI                        |
| **Coqui TTS**       | Speech synthesis & voice cloning   |
| **Deep Translator** | Automatic translation              |
| **Pydub**           | Audio conversion and preprocessing |
| **Uvicorn**         | ASGI server for FastAPI            |

---

### âš™ï¸ **System Requirements**

* Python 3.10 or 3.11
* 8GB+ RAM recommended
* Windows / macOS / Linux
* No GPU required (runs fully on CPU)

---

### ğŸ“Š **Results**

* Natural and fluent speech output in supported languages.
* High-quality zero-shot voice cloning with short input samples.
* Runs efficiently on CPU-based systems without CUDA dependencies.

---

### ğŸ§­ **Future Enhancements**

* Add **Hindi, Spanish, and German** support.
* Integrate **XTTS** for broader multilingual synthesis.
* Implement **speaker emotion control** (happy, sad, neutral).
* Deploy on web using **Render / Hugging Face Spaces**.

---

### ğŸ‘¨â€ğŸ’» **Author**

**Rishabh Upadhyay**
ğŸ“ M.Tech Artificial Intelligence â€“ Amity University Noida
ğŸ“§ [GitHub Profile](https://github.com/Rishabhupadhyay28)
